{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a572d59-ca8f-4573-aaeb-0567a7435eb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name, current_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9175299-4fae-415f-9d0b-7b832cad75bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_tables = {\n",
    "    \"departments\": [\"dbfs:/mnt/raw/departments/\", \"dept_no\"],\n",
    "    \"dept_emp\": [\"dbfs:/mnt/raw/dept_emp/\", \"emp_no, dept_no\"],  \n",
    "    \"dept_manager\": [\"dbfs:/mnt/raw/dept_manager/\", \"emp_no, dept_no\"],  \n",
    "    \"employees\": [\"dbfs:/mnt/raw/employees/\", \"emp_no\"],\n",
    "    \"salaries\": [\"dbfs:/mnt/raw/salaries/\", \"emp_no, from_date\"],  \n",
    "    \"titles\": [\"dbfs:/mnt/raw/titles/\", \"emp_no, from_date\"]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945a6f0f-8343-4145-b088-6c8618350ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS employee_catalog.raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad5e8c67-e5ad-42d5-8b43-59311bd94701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# update employee_catalog.silver.employees\n",
    "# set first_name = 'Chidera'\n",
    "# where emp_no = 10001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27db6027-10a1-478a-8693-5744d968fcfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>emp_no</th><th>first_name</th><th>last_name</th><th>gender</th><th>hire_date</th><th>birth_date</th><th>updated_at</th><th>full_name</th><th>load_date</th></tr></thead><tbody><tr><td>10001</td><td>Georgi</td><td>Facello</td><td>M</td><td>1986-06-26</td><td>1953-09-02</td><td>2025-02-12T15:07:18Z</td><td>Georgi Facello</td><td>2025-02-12T14:46:50.424Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "10001",
         "Georgi",
         "Facello",
         "M",
         "1986-06-26",
         "1953-09-02",
         "2025-02-12T15:07:18Z",
         "Georgi Facello",
         "2025-02-12T14:46:50.424Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 67
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "emp_no",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "hire_date",
         "type": "\"date\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{\"comment\":\"The updated_at column in this table tracks the most recent update made to an employee's record. This information is important for auditing purposes and can be useful for tracking changes made within the HR system by different users over time.\"}",
         "name": "updated_at",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "load_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select *\n",
    "from employee_catalog.silver.employees\n",
    "where emp_no = 10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "641b2198-b128-4841-a6ae-3ceb05f43a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incrementally loaded departments into employee_catalog.raw.departments with SCD Type 1\nIncrementally loaded dept_emp into employee_catalog.raw.dept_emp with SCD Type 1\nIncrementally loaded dept_manager into employee_catalog.raw.dept_manager with SCD Type 1\nIncrementally loaded employees into employee_catalog.raw.employees with SCD Type 1\nIncrementally loaded salaries into employee_catalog.raw.salaries with SCD Type 1\nIncrementally loaded titles into employee_catalog.raw.titles with SCD Type 1\n"
     ]
    }
   ],
   "source": [
    "for table, table_info in raw_tables.items():\n",
    "    path = table_info[0]\n",
    "    primary_key = table_info[1]\n",
    "    primary_key_cols = [col.strip() for col in primary_key.split(\",\")]\n",
    "\n",
    "    df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(path) \\\n",
    "    .withColumn(\"_file_name\", input_file_name()) \\\n",
    "    .withColumn(\"load_date\", current_timestamp())\n",
    "\n",
    "    # Create a temporary view with only the latest record for each primary key\n",
    "    dedup_query = f\"\"\"\n",
    "    WITH RankedRecords AS (\n",
    "        SELECT *,\n",
    "               ROW_NUMBER() OVER (\n",
    "                   PARTITION BY {\", \".join(primary_key_cols)}\n",
    "                   ORDER BY _airbyte_emitted_at DESC\n",
    "               ) as rn\n",
    "        FROM temp_view\n",
    "    )\n",
    "    SELECT {\", \".join(df.columns)}\n",
    "    FROM RankedRecords\n",
    "    WHERE rn = 1\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # creating temp view to compare data\n",
    "    df.createOrReplaceTempView(\"temp_view\")\n",
    "\n",
    "    # Create a new temp view with deduplicated records\n",
    "    spark.sql(dedup_query).createOrReplaceTempView(\"deduplicated_source\")\n",
    "\n",
    " \n",
    "    target_table = f\"employee_catalog.raw.{table}\"\n",
    "\n",
    "    # spark.sql(f\"TRUNCATE TABLE {target_table}\")\n",
    "\n",
    "\n",
    "    # merge statement to implement scd type 1\n",
    "    merge_query = f\"\"\"\n",
    "    MERGE INTO {target_table} AS target\n",
    "    USING deduplicated_source AS source\n",
    "    ON {\" AND \".join([f\"target.{col.strip()} = source.{col.strip()}\" for col in primary_key_cols])}\n",
    "    WHEN MATCHED \n",
    "        AND source._airbyte_emitted_at > target._airbyte_emitted_at\n",
    "    THEN\n",
    "        UPDATE SET {\", \".join([f\"target.{col} = source.{col}\" for col in df.columns])}\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT ({\", \".join(df.columns)}) \n",
    "        VALUES ({\", \".join([f\"source.{col}\" for col in df.columns])})\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the MERGE statement\n",
    "    spark.sql(merge_query)\n",
    "\n",
    "    print(f\"Incrementally loaded {table} into employee_catalog.raw.{table} with SCD Type 1\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7361051395124746,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Staging ETL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}